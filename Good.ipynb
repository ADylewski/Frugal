{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Install deps (Kaggle / Colab)\n",
    "# =========================\n",
    "# If you're on Kaggle, you can run this in a notebook cell.\n",
    "!pip -q install opencv-python-headless scikit-learn mlxtend tqdm scikit-image kagglehub \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903a74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Imports\n",
    "# =========================\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "from typing import Dict, Iterable, List, Sequence, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from skimage.feature import local_binary_pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0447c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# A) Config + reproducibility\n",
    "# =========================\n",
    "MODE = \"quick\"  # \"quick\" or \"full\"\n",
    "SEED = 0\n",
    "\n",
    "# Dataset path (file or folder)\n",
    "PATH_RAW = \"/Users/dylesm/.cache/kagglehub/datasets/vesuvius13/formula-one-cars/versions/1/\"\n",
    "DATA_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n",
    "\n",
    "# Image preprocessing\n",
    "IMG_SIZE = (256, 256)\n",
    "PATCH = 16\n",
    "\n",
    "# Clustering\n",
    "K = 150\n",
    "KMEANS_BATCH_SIZE = 4096\n",
    "KMEANS_RANDOM_STATE = 0\n",
    "PATCHES_PER_IMAGE = 64\n",
    "\n",
    "# Association rule mining\n",
    "NEIGH = 2\n",
    "MIN_SUPPORT = 0.001\n",
    "MIN_CONF = 0.08\n",
    "MIN_SYM_CONF = 0.0# stopping threshold for avg symmetric confidence\n",
    "MERGE_ITERS = 60\n",
    "METRICS_EVERY = 1  # compute metrics every N merges\n",
    "CONF_CURVE_EVERY = 1\n",
    "\n",
    "# Dense/sparse mining controls (explicit, never silent)\n",
    "USE_SPARSE_TE = True\n",
    "MAX_DENSE_CELLS = 25_000_000  # if n_tx * n_items exceeds this, use sparse\n",
    "ITEM_FILTER_TOP_N = None  # set to int to keep only top-N items (explicit)\n",
    "\n",
    "# Pairwise sim / discriminative power controls\n",
    "PAIRWISE_SAMPLE_PAIRS = 50000  # <=0 for exact only\n",
    "PAIRWISE_EXACT_MAX_DOCS = 400\n",
    "DISC_POWER_SAMPLE_SIZE = None  # set to int to sample objects; None => exact\n",
    "\n",
    "# Output and visualization\n",
    "OUTPUT_DIR = \"./outputs_assocphrases\"\n",
    "FIG_SUBDIR = \"paper_figures\"\n",
    "WORD_LUT_SEED = 42\n",
    "ALPHA = 0.45\n",
    "N_SHOW_LIMIT = 12\n",
    "N_VIZ_LIMIT = 30\n",
    "N_CROP_VIZ_LIMIT = 80\n",
    "N_OVERLAY_LIMIT = 30\n",
    "\n",
    "# Quick/full overrides\n",
    "if MODE == \"quick\":\n",
    "    MAX_IMAGES = 100\n",
    "    K = 80\n",
    "    PATCHES_PER_IMAGE = 16\n",
    "    MERGE_ITERS = 60\n",
    "    MIN_SUPPORT = 0.003\n",
    "else:\n",
    "    MAX_IMAGES = 250\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a49cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/dylesm/.cache/kagglehub/datasets/vesuvius13/formula-one-cars/versions/1\n",
      "Found images: 2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01<00:00, 56.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 100 in 1.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# B) Data loading + sampling\n",
    "# =========================\n",
    "\n",
    "def find_images(root: str) -> List[str]:\n",
    "    '''Collect all image paths under root.'''\n",
    "    paths: List[str] = []\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        for fn in filenames:\n",
    "            if fn.lower().endswith(DATA_EXTS):\n",
    "                paths.append(os.path.join(dirpath, fn))\n",
    "    return paths\n",
    "\n",
    "path = os.path.normpath(os.path.expanduser(PATH_RAW))\n",
    "if os.path.isfile(path):\n",
    "    path = os.path.dirname(path)\n",
    "if not os.path.exists(path):\n",
    "    raise FileNotFoundError(f\"Path does not exist: {path}\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "image_paths = find_images(path)\n",
    "print(\"Found images:\", len(image_paths))\n",
    "\n",
    "random.shuffle(image_paths)\n",
    "image_paths_small = image_paths[: min(MAX_IMAGES, len(image_paths))]\n",
    "\n",
    "\n",
    "def load_image_bgr(path: str, size: Tuple[int, int] = IMG_SIZE) -> np.ndarray:\n",
    "    '''Load and resize an image to IMG_SIZE.'''\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "start = time.time()\n",
    "imgs: List[np.ndarray] = []\n",
    "kept_paths: List[str] = []\n",
    "for p in tqdm(image_paths_small):\n",
    "    im = load_image_bgr(p)\n",
    "    if im is not None:\n",
    "        imgs.append(im)\n",
    "        kept_paths.append(p)\n",
    "\n",
    "print(\"Loaded:\", len(imgs), \"in\", round(time.time() - start, 2), \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f10ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches: 256 Grid: (16, 16)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# C) Patch extraction\n",
    "# =========================\n",
    "\n",
    "def image_to_patches(img_bgr: np.ndarray, patch: int = PATCH) -> Tuple[List[np.ndarray], List[Tuple[int, int]], Tuple[int, int]]:\n",
    "    '''Split image into square patches and return (patches, coords, grid_shape).'''\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    assert h % patch == 0 and w % patch == 0, \"Image size must be divisible by patch size\"\n",
    "    patches: List[np.ndarray] = []\n",
    "    coords: List[Tuple[int, int]] = []\n",
    "    for y in range(0, h, patch):\n",
    "        for x in range(0, w, patch):\n",
    "            patches.append(img_bgr[y:y+patch, x:x+patch])\n",
    "            coords.append((y // patch, x // patch))\n",
    "    return patches, coords, (h // patch, w // patch)\n",
    "\n",
    "patches0, coords0, grid0 = image_to_patches(imgs[0])\n",
    "print(\"Patches:\", len(patches0), \"Grid:\", grid0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc56014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# D1) Feature extraction config (HSV)\n",
    "# =========================\n",
    "HSV_H_BINS = 8\n",
    "HSV_S_BINS = 8\n",
    "HSV_V_BINS = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cb087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# D2) Feature extraction config (LBP)\n",
    "# =========================\n",
    "LBP_P = 8\n",
    "LBP_R = 1\n",
    "LBP_METHOD = \"uniform\"\n",
    "LBP_BINS = LBP_P + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bda90d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dim: (522,)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# D) Feature extraction\n",
    "# =========================\n",
    "\n",
    "def hsv_hist(patch_bgr: np.ndarray, h_bins: int = HSV_H_BINS, s_bins: int = HSV_S_BINS, v_bins: int = HSV_V_BINS) -> np.ndarray:\n",
    "    '''HSV histogram normalized to sum to 1.'''\n",
    "    hsv = cv2.cvtColor(patch_bgr, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, [h_bins, s_bins, v_bins], [0, 180, 0, 256, 0, 256])\n",
    "    hist = hist.flatten().astype(np.float32)\n",
    "    hist /= (hist.sum() + 1e-8)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def lbp_hist(patch_bgr: np.ndarray) -> np.ndarray:\n",
    "    '''Local Binary Pattern histogram normalized to sum to 1.'''\n",
    "    gray = cv2.cvtColor(patch_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray, P=LBP_P, R=LBP_R, method=LBP_METHOD)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, LBP_BINS + 1), range=(0, LBP_BINS))\n",
    "    hist = hist.astype(np.float32)\n",
    "    hist /= (hist.sum() + 1e-8)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def patch_features(patch_bgr: np.ndarray) -> np.ndarray:\n",
    "    '''Concatenate color and texture descriptors for a patch.'''\n",
    "    return np.concatenate([hsv_hist(patch_bgr), lbp_hist(patch_bgr)], axis=0)\n",
    "\n",
    "feat0 = patch_features(patches0[0])\n",
    "print(\"Feature dim:\", feat0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90628247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00<00:00, 1162.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patch samples: (1600, 522) in 0.09 s\n",
      "Trained kmeans with K = 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01<00:00, 79.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example grid shape: (16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# E) Visual-word quantization (k-means)\n",
    "# =========================\n",
    "\n",
    "def build_feature_matrix(imgs: Sequence[np.ndarray]) -> np.ndarray:\n",
    "    '''Build feature matrix from patches across images.'''\n",
    "    all_feats: List[np.ndarray] = []\n",
    "    for img in tqdm(imgs):\n",
    "        patches, _, _ = image_to_patches(img)\n",
    "        idxs = list(range(len(patches)))\n",
    "        if len(idxs) > PATCHES_PER_IMAGE:\n",
    "            idxs = random.sample(idxs, PATCHES_PER_IMAGE)\n",
    "        for j in idxs:\n",
    "            all_feats.append(patch_features(patches[j]))\n",
    "    return np.vstack(all_feats)\n",
    "\n",
    "start = time.time()\n",
    "X = build_feature_matrix(imgs)\n",
    "print(\"Total patch samples:\", X.shape, \"in\", round(time.time() - start, 2), \"s\")\n",
    "\n",
    "kmeans = MiniBatchKMeans(\n",
    "    n_clusters=K,\n",
    "    batch_size=KMEANS_BATCH_SIZE,\n",
    "    random_state=KMEANS_RANDOM_STATE\n",
    ")\n",
    "kmeans.fit(X)\n",
    "print(\"Trained kmeans with K =\", K)\n",
    "\n",
    "\n",
    "def image_words_grid(img_bgr: np.ndarray, patch: int = PATCH) -> np.ndarray:\n",
    "    '''Assign a word ID to each patch.'''\n",
    "    patches, _, (gh, gw) = image_to_patches(img_bgr, patch=patch)\n",
    "    feats = np.vstack([patch_features(p) for p in patches])\n",
    "    words = kmeans.predict(feats)\n",
    "    grid = words.reshape(gh, gw)\n",
    "    return grid\n",
    "\n",
    "word_grids: List[np.ndarray] = []\n",
    "for img in tqdm(imgs):\n",
    "    word_grids.append(image_words_grid(img))\n",
    "\n",
    "print(\"Example grid shape:\", word_grids[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c1dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transactions: 25600 in 0.09 s\n",
      "Example transaction: ['w38', 'w8', 'w44', 'w17', 'w63']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# F) Transaction building (local windows)\n",
    "# =========================\n",
    "\n",
    "def local_transactions_from_grid(grid: np.ndarray, neigh: int = NEIGH) -> List[List[str]]:\n",
    "    '''Create transactions from local neighborhoods in a grid.'''\n",
    "    gh, gw = grid.shape\n",
    "    tx: List[List[str]] = []\n",
    "    for r in range(gh):\n",
    "        for c in range(gw):\n",
    "            r0, r1 = max(0, r - neigh), min(gh, r + neigh + 1)\n",
    "            c0, c1 = max(0, c - neigh), min(gw, c + neigh + 1)\n",
    "            window = grid[r0:r1, c0:c1].ravel()\n",
    "            items = list(set(int(x) for x in window))\n",
    "            items = [f\"w{it}\" for it in items]\n",
    "            tx.append(items)\n",
    "    return tx\n",
    "\n",
    "\n",
    "def build_transactions_per_image(word_grids: Sequence[np.ndarray], neigh: int = NEIGH) -> List[List[List[str]]]:\n",
    "    '''Build transactions for each image.'''\n",
    "    return [local_transactions_from_grid(grid, neigh=neigh) for grid in word_grids]\n",
    "\n",
    "start = time.time()\n",
    "transactions_per_image = build_transactions_per_image(word_grids, neigh=NEIGH)\n",
    "transactions = [t for tx in transactions_per_image for t in tx]\n",
    "print(\"Total transactions:\", len(transactions), \"in\", round(time.time() - start, 2), \"s\")\n",
    "print(\"Example transaction:\", transactions[0][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5cff7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules: 49845 Pair rules: 1064 in 19.68 s\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# G) Rule mining\n",
    "# =========================\n",
    "\n",
    "def mine_rules(transactions: Sequence[Sequence[str]], min_support: float, min_conf: float) -> Tuple[object, object]:\n",
    "    '''Mine frequent itemsets and association rules.'''\n",
    "    items = sorted({i for tx in transactions for i in tx})\n",
    "    if ITEM_FILTER_TOP_N is not None:\n",
    "        counts = {i: 0 for i in items}\n",
    "        for tx in transactions:\n",
    "            for i in set(tx):\n",
    "                counts[i] += 1\n",
    "        top_items = set(sorted(counts, key=counts.get, reverse=True)[:ITEM_FILTER_TOP_N])\n",
    "        transactions = [[i for i in tx if i in top_items] for tx in transactions]\n",
    "        items = sorted(top_items)\n",
    "        print(f\"[WARN] ITEM_FILTER_TOP_N enabled -> keeping {len(items)} items\")\n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    use_sparse = USE_SPARSE_TE\n",
    "    if len(transactions) * max(1, len(items)) > MAX_DENSE_CELLS:\n",
    "        use_sparse = True\n",
    "        print(\"[INFO] Using sparse TransactionEncoder due to size\")\n",
    "\n",
    "    T = te.fit(transactions).transform(transactions, sparse=use_sparse)\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n",
    "\n",
    "    freq = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(freq, metric=\"confidence\", min_threshold=min_conf)\n",
    "    rules = rules.sort_values([\"confidence\", \"lift\", \"support\"], ascending=False)\n",
    "    return freq, rules\n",
    "\n",
    "\n",
    "def is_singleton(fs: object) -> bool:\n",
    "    return isinstance(fs, (set, frozenset)) and len(fs) == 1\n",
    "\n",
    "\n",
    "def extract_pair_rules(rules_df) -> object:\n",
    "    '''Filter rules with single-item antecedent and consequent.'''\n",
    "    return rules_df[\n",
    "        rules_df[\"antecedents\"].apply(is_singleton) &\n",
    "        rules_df[\"consequents\"].apply(is_singleton)\n",
    "    ].copy()\n",
    "\n",
    "\n",
    "def best_symmetric_pair(pair_rules) -> Tuple[float, float, str, str]:\n",
    "    '''Return (avg_conf, support, a, b) for best symmetric pair, or None.'''\n",
    "    conf_map: Dict[Tuple[str, str], float] = {}\n",
    "    sup_map: Dict[Tuple[str, str], float] = {}\n",
    "    for _, row in pair_rules.iterrows():\n",
    "        a = next(iter(row[\"antecedents\"]))\n",
    "        b = next(iter(row[\"consequents\"]))\n",
    "        conf_map[(a, b)] = float(row[\"confidence\"])\n",
    "        sup_map[(a, b)] = float(row[\"support\"])\n",
    "\n",
    "    best = None\n",
    "    for (a, b), cab in conf_map.items():\n",
    "        cba = conf_map.get((b, a))\n",
    "        if cba is None:\n",
    "            continue\n",
    "        avg_conf = 0.5 * (cab + cba)\n",
    "        sup = 0.5 * (sup_map.get((a, b), 0.0) + sup_map.get((b, a), 0.0))\n",
    "        if (best is None) or (avg_conf > best[0]):\n",
    "            best = (avg_conf, sup, a, b)\n",
    "    return best\n",
    "\n",
    "start = time.time()\n",
    "_, rules = mine_rules(transactions, MIN_SUPPORT, MIN_CONF)\n",
    "pair_rules = extract_pair_rules(rules)\n",
    "print(\"Rules:\", len(rules), \"Pair rules:\", len(pair_rules), \"in\", round(time.time() - start, 2), \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e2b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: merge w17<->w19 avg_conf=0.799 support=0.5297 tx_changed=13560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: merge w20<->w0 avg_conf=0.682 support=0.0317 tx_changed=812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2: merge w33<->w5 avg_conf=0.676 support=0.0530 tx_changed=1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3: merge w2<->w67 avg_conf=0.635 support=0.0713 tx_changed=1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4: merge w68<->w71 avg_conf=0.627 support=0.0227 tx_changed=580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5: merge w7<->w36 avg_conf=0.603 support=0.1007 tx_changed=2579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6: merge w10<->w72 avg_conf=0.592 support=0.0584 tx_changed=1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7: merge w3<->w55 avg_conf=0.569 support=0.0313 tx_changed=802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8: merge w28<->w23 avg_conf=0.535 support=0.0270 tx_changed=691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9: merge w32<->w47 avg_conf=0.513 support=0.0167 tx_changed=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10: merge w33<->w79 avg_conf=0.510 support=0.0149 tx_changed=382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11: merge w26<->w75 avg_conf=0.509 support=0.0110 tx_changed=282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12: merge w9<->w45 avg_conf=0.506 support=0.0331 tx_changed=848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 13: merge w39<->w63 avg_conf=0.504 support=0.0425 tx_changed=1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 14: merge w46<->p0(w17+w19) avg_conf=0.493 support=0.1544 tx_changed=3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15: merge w12<->w78 avg_conf=0.471 support=0.0059 tx_changed=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 16: merge w79<->p3(w2+w67) avg_conf=0.459 support=0.0225 tx_changed=575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 17: merge w8<->w44 avg_conf=0.452 support=0.0197 tx_changed=505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18: merge w47<->w1 avg_conf=0.438 support=0.0343 tx_changed=878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 19: merge w24<->w61 avg_conf=0.426 support=0.0150 tx_changed=383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20: merge w11<->w40 avg_conf=0.422 support=0.0080 tx_changed=205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21: merge w53<->p1(w20+w0) avg_conf=0.410 support=0.0095 tx_changed=243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 22: merge w79<->p2(w33+w5) avg_conf=0.408 support=0.0094 tx_changed=241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 23: merge w27<->w31 avg_conf=0.403 support=0.0080 tx_changed=205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 24: merge w58<->w8 avg_conf=0.396 support=0.0036 tx_changed=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 25: merge w8<->p10(w33+w79) avg_conf=0.448 support=0.0047 tx_changed=121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 26: merge w76<->w13 avg_conf=0.394 support=0.0155 tx_changed=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 27: merge w36<->p0(w17+w19) avg_conf=0.394 support=0.1201 tx_changed=3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 28: merge w49<->w30 avg_conf=0.380 support=0.0066 tx_changed=169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 29: merge w76<->w66 avg_conf=0.372 support=0.0099 tx_changed=253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30: merge w59<->w14 avg_conf=0.364 support=0.0079 tx_changed=201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 31: merge p16(w79+p3(w2+w67))<->p2(w33+w5) avg_conf=0.358 support=0.0106 tx_changed=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 32: merge p14(w46+p0(w17+w19))<->w77 avg_conf=0.355 support=0.0718 tx_changed=1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 33: merge p2(w33+w5)<->p3(w2+w67) avg_conf=0.352 support=0.0139 tx_changed=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 34: merge p2(w33+w5)<->w2 avg_conf=0.390 support=0.0092 tx_changed=235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 35: merge w33<->p3(w2+w67) avg_conf=0.372 support=0.0035 tx_changed=89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 36: merge w60<->w52 avg_conf=0.338 support=0.0065 tx_changed=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 37: merge w6<->w29 avg_conf=0.335 support=0.0095 tx_changed=242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 38: merge w29<->w22 avg_conf=0.349 support=0.0156 tx_changed=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 39: merge w71<->w45 avg_conf=0.334 support=0.0221 tx_changed=567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40: merge w46<->w19 avg_conf=0.332 support=0.0326 tx_changed=835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 41: merge w46<->w17 avg_conf=0.460 support=0.0237 tx_changed=606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 42: merge w9<->w48 avg_conf=0.328 support=0.0036 tx_changed=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 43: merge w42<->w70 avg_conf=0.319 support=0.0059 tx_changed=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 44: merge w22<->p5(w7+w36) avg_conf=0.310 support=0.0171 tx_changed=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 45: merge w73<->w55 avg_conf=0.306 support=0.0094 tx_changed=240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 46: merge p10(w33+w79)<->p3(w2+w67) avg_conf=0.302 support=0.0046 tx_changed=119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 47: merge p38(w29+w22)<->w15 avg_conf=0.301 support=0.0075 tx_changed=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 48: merge w41<->w37 avg_conf=0.300 support=0.0062 tx_changed=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 49: merge p3(w2+w67)<->w5 avg_conf=0.300 support=0.0087 tx_changed=222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50: merge w36<->w19 avg_conf=0.299 support=0.0420 tx_changed=1075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 51: merge p32(p14(w46+p0(w17+w19))+w77)<->w36 avg_conf=0.306 support=0.0250 tx_changed=640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 52: merge w36<->p14(w46+p0(w17+w19)) avg_conf=0.304 support=0.0230 tx_changed=590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 53: merge w77<->p0(w17+w19) avg_conf=0.299 support=0.0709 tx_changed=1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 54: merge p27(w36+p0(w17+w19))<->w77 avg_conf=0.303 support=0.0405 tx_changed=1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 55: merge p41(w46+w17)<->w77 avg_conf=0.297 support=0.0116 tx_changed=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 56: merge p7(w3+w55)<->w15 avg_conf=0.297 support=0.0116 tx_changed=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 57: merge w56<->w30 avg_conf=0.291 support=0.0094 tx_changed=241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 58: merge w16<->p13(w39+w63) avg_conf=0.284 support=0.0119 tx_changed=305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 59: merge w31<->w43 avg_conf=0.279 support=0.0086 tx_changed=219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60: stop (no symmetric pair or max iters)\n",
      "Merge loop done in 262.13 s\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# H) Symmetric merge loop\n",
    "# =========================\n",
    "\n",
    "def doc_sets_from_transactions(tx_per_image: Sequence[Sequence[Sequence[str]]]) -> List[Set[str]]:\n",
    "    '''Build per-image document token sets from transactions.'''\n",
    "    doc_sets: List[Set[str]] = []\n",
    "    for tx in tx_per_image:\n",
    "        s: Set[str] = set()\n",
    "        for items in tx:\n",
    "            s.update(items)\n",
    "        doc_sets.append(s)\n",
    "    return doc_sets\n",
    "\n",
    "\n",
    "def apply_merge_to_tx_per_image(tx_per_image: Sequence[Sequence[Sequence[str]]], a: str, b: str, new_token: str) -> Tuple[List[List[List[str]]], int]:\n",
    "    '''Apply merge to all transactions per image; returns (new_tx, changed_count).'''\n",
    "    out: List[List[List[str]]] = []\n",
    "    changed = 0\n",
    "    for tx in tx_per_image:\n",
    "        out_tx: List[List[str]] = []\n",
    "        for items in tx:\n",
    "            s = set(items)\n",
    "            if a in s and b in s:\n",
    "                s.remove(a); s.remove(b)\n",
    "                s.add(new_token)\n",
    "                changed += 1\n",
    "            out_tx.append(list(s))\n",
    "        out.append(out_tx)\n",
    "    return out, changed\n",
    "\n",
    "\n",
    "def apply_merge_to_doc_sets(doc_sets: Sequence[Set[str]], a: str, b: str, new_token: str) -> List[Set[str]]:\n",
    "    '''Apply merge to per-image token sets.'''\n",
    "    out: List[Set[str]] = []\n",
    "    for s in doc_sets:\n",
    "        s2 = set(s)\n",
    "        if a in s2 and b in s2:\n",
    "            s2.remove(a); s2.remove(b)\n",
    "            s2.add(new_token)\n",
    "        out.append(s2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def merge_loop(tx_per_image: Sequence[Sequence[Sequence[str]]], iters: int) -> Tuple[List[Dict], List[Set[str]]]:\n",
    "    '''Run symmetric merges and return iteration logs and final doc sets.'''\n",
    "    logs: List[Dict] = []\n",
    "    current_tx = tx_per_image\n",
    "    current_docs = doc_sets_from_transactions(current_tx)\n",
    "    phrase_members: Dict[str, Set[int]] = {}\n",
    "    phrase_tokens: List[str] = []\n",
    "\n",
    "    def token_members(token: str) -> Set[int]:\n",
    "        if token.startswith(\"w\"):\n",
    "            return {int(token[1:])}\n",
    "        if token in phrase_members:\n",
    "            return set(phrase_members[token])\n",
    "        return set()\n",
    "\n",
    "    for t in range(iters + 1):\n",
    "        tx_flat = [t for tx in current_tx for t in tx]\n",
    "        _, rules_df = mine_rules(tx_flat, MIN_SUPPORT, MIN_CONF)\n",
    "        pair_rules = extract_pair_rules(rules_df)\n",
    "        best = best_symmetric_pair(pair_rules)\n",
    "\n",
    "        vocab_size = len(set().union(*current_docs)) if current_docs else 0\n",
    "        log_row = {\n",
    "            \"iter\": t,\n",
    "            \"num_rules\": int(len(rules_df)),\n",
    "            \"num_pair_rules\": int(len(pair_rules)),\n",
    "            \"vocab_size\": int(vocab_size),\n",
    "            \"best_pair\": None,\n",
    "            \"avg_sym_conf\": None,\n",
    "            \"support\": None,\n",
    "            \"tx_changed\": 0,\n",
    "            \"new_token\": None,\n",
    "            \"members\": None,\n",
    "        }\n",
    "\n",
    "        if best is None or t == iters:\n",
    "            logs.append(log_row)\n",
    "            print(f\"Iter {t}: stop (no symmetric pair or max iters)\")\n",
    "            break\n",
    "\n",
    "        avg_conf, sup, a, b = best\n",
    "        if avg_conf < MIN_SYM_CONF:\n",
    "            logs.append(log_row)\n",
    "            print(f\"Iter {t}: stop (avg_sym_conf {avg_conf:.3f} < MIN_SYM_CONF)\")\n",
    "            break\n",
    "\n",
    "        new_token = f\"p{t}({a}+{b})\"\n",
    "        members = sorted(token_members(a) | token_members(b))\n",
    "        current_tx, changed = apply_merge_to_tx_per_image(current_tx, a, b, new_token)\n",
    "        current_docs = apply_merge_to_doc_sets(current_docs, a, b, new_token)\n",
    "\n",
    "        phrase_members[new_token] = set(members)\n",
    "        phrase_tokens.append(new_token)\n",
    "\n",
    "        log_row.update({\n",
    "            \"best_pair\": f\"{a},{b}\",\n",
    "            \"avg_sym_conf\": float(avg_conf),\n",
    "            \"support\": float(sup),\n",
    "            \"tx_changed\": int(changed),\n",
    "            \"vocab_size\": int(len(set().union(*current_docs)) if current_docs else 0),\n",
    "            \"new_token\": new_token,\n",
    "            \"members\": members,\n",
    "        })\n",
    "        logs.append(log_row)\n",
    "        print(f\"Iter {t}: merge {a}<->{b} avg_conf={avg_conf:.3f} support={sup:.4f} tx_changed={changed}\")\n",
    "\n",
    "    return logs, current_docs\n",
    "\n",
    "start = time.time()\n",
    "merge_logs, final_doc_sets = merge_loop(transactions_per_image, MERGE_ITERS)\n",
    "print(\"Merge loop done in\", round(time.time() - start, 2), \"s\")\n",
    "\n",
    "# Build phrase member mapping from merge logs\n",
    "PHRASE_MEMBERS = {m[\"new_token\"]: m[\"members\"] for m in merge_logs if m.get(\"new_token\")}\n",
    "PHRASE_TOKENS = list(PHRASE_MEMBERS.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4f26962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:58: DeprecationWarning: invalid escape sequence '\\ '\n",
      "<>:58: DeprecationWarning: invalid escape sequence '\\ '\n",
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/4183716311.py:58: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  '''Average density(D) - density(D \\ o) across objects.'''\n",
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/1075797498.py:26: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df = pd.DataFrame.sparse.from_spmatrix(T, columns=te.columns_) if use_sparse else pd.DataFrame(T, columns=te.columns_)\n",
      "/var/folders/xx/37z511cj2fq2x3d7t5_023ww0000gn/T/ipykernel_24205/4183716311.py:58: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  '''Average density(D) - density(D \\ o) across objects.'''\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 138\u001b[39m\n\u001b[32m    136\u001b[39m     fig_dir = os.path.join(OUTPUT_DIR, FIG_SUBDIR)\n\u001b[32m    137\u001b[39m     os.makedirs(fig_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[43mplot_confidence_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrules_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfig3_confidence_iter\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m best = best_symmetric_pair(pair_rules)\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m t == MERGE_ITERS:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mplot_confidence_curve\u001b[39m\u001b[34m(rules_df, out_path)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''Plot Fig.3-style confidence curve.'''\u001b[39;00m\n\u001b[32m     78\u001b[39m conf_vals = rules_df[\u001b[33m\"\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m\"\u001b[39m].sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).values\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m fig, ax = \u001b[43mplt\u001b[49m.subplots(figsize=(\u001b[32m7\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m     80\u001b[39m ax.plot(np.arange(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(conf_vals) + \u001b[32m1\u001b[39m), conf_vals, color=\u001b[33m\"\u001b[39m\u001b[33mnavy\u001b[39m\u001b[33m\"\u001b[39m, lw=\u001b[32m2\u001b[39m)\n\u001b[32m     81\u001b[39m ax.set_xlabel(\u001b[33m\"\u001b[39m\u001b[33mRule rank\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# I) Evaluation + plots\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.pyplot as plt\n",
    "# =========================\n",
    "\n",
    "def build_doc_matrix(doc_sets: Sequence[Set[str]]) -> Tuple[np.ndarray, List[str]]:\n",
    "    '''Build binary document-term matrix for images.'''\n",
    "    vocab = sorted(set().union(*doc_sets)) if doc_sets else []\n",
    "    idx = {t: i for i, t in enumerate(vocab)}\n",
    "    X = np.zeros((len(doc_sets), len(vocab)), dtype=np.float64)\n",
    "    for i, s in enumerate(doc_sets):\n",
    "        for t in s:\n",
    "            X[i, idx[t]] = 1.0\n",
    "    return X, vocab\n",
    "\n",
    "\n",
    "def density_from_matrix(X: np.ndarray) -> float:\n",
    "    '''Average cosine similarity between each document and the centroid.'''\n",
    "    if X.size == 0:\n",
    "        return 0.0\n",
    "    eps = 1e-12\n",
    "    norms = np.linalg.norm(X, axis=1) + eps\n",
    "    Xn = X / norms[:, None]\n",
    "    centroid = X.mean(axis=0)\n",
    "    c_norm = np.linalg.norm(centroid) + eps\n",
    "    sims = (Xn @ centroid) / c_norm\n",
    "    return float(np.mean(sims))\n",
    "\n",
    "\n",
    "def avg_pairwise_distance(X: np.ndarray, sample_pairs: int = PAIRWISE_SAMPLE_PAIRS) -> float:\n",
    "    '''Average cosine distance (1 - similarity) for i<=j (exact if small, else sampled).'''\n",
    "    n = X.shape[0]\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    eps = 1e-12\n",
    "    norms = np.linalg.norm(X, axis=1) + eps\n",
    "    Xn = X / norms[:, None]\n",
    "\n",
    "    if n <= PAIRWISE_EXACT_MAX_DOCS or sample_pairs <= 0:\n",
    "        sim = Xn @ Xn.T\n",
    "        k = n * (n + 1) / 2.0\n",
    "        total = (np.sum(sim) + np.sum(np.diag(sim))) / 2.0\n",
    "        return float(1.0 - (total / k))\n",
    "\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    sims = []\n",
    "    for _ in range(sample_pairs):\n",
    "        i = rng.integers(0, n)\n",
    "        j = rng.integers(0, n)\n",
    "        if j < i:\n",
    "            i, j = j, i\n",
    "        sims.append(float(np.dot(Xn[i], Xn[j])))\n",
    "    return float(1.0 - np.mean(sims))\n",
    "\n",
    "\n",
    "def avg_discriminative_power(X: np.ndarray) -> float:\n",
    "    '''Average density(D) - density(D \\ o) across objects.'''\n",
    "    if X.size == 0:\n",
    "        return 0.0\n",
    "    density_full = density_from_matrix(X)\n",
    "    m = X.shape[1]\n",
    "    cols = list(range(m))\n",
    "    if DISC_POWER_SAMPLE_SIZE is not None and DISC_POWER_SAMPLE_SIZE < m:\n",
    "        rng = np.random.default_rng(SEED)\n",
    "        cols = rng.choice(m, size=DISC_POWER_SAMPLE_SIZE, replace=False).tolist()\n",
    "        print(f\"[INFO] Discriminative power sampled: {len(cols)}/{m}\")\n",
    "    diffs = []\n",
    "    for col in cols:\n",
    "        X2 = X.copy()\n",
    "        X2[:, col] = 0.0\n",
    "        diffs.append(density_full - density_from_matrix(X2))\n",
    "    return float(np.mean(diffs)) if diffs else 0.0\n",
    "\n",
    "\n",
    "def plot_confidence_curve(rules_df, out_path: str) -> None:\n",
    "    '''Plot Fig.3-style confidence curve.'''\n",
    "    conf_vals = rules_df[\"confidence\"].sort_values(ascending=False).values\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.plot(np.arange(1, len(conf_vals) + 1), conf_vals, color=\"navy\", lw=2)\n",
    "    ax.set_xlabel(\"Rule rank\")\n",
    "    ax.set_ylabel(\"Confidence value\")\n",
    "    ax.grid(True, color=\"#dddddd\", linewidth=0.8)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "def plot_metric_curves(metrics_rows: List[Dict], out_path: str) -> None:\n",
    "    '''Plot Fig.4-style metric curves over merges vs |O|.'''\n",
    "    x_vals = [r[\"vocab_size\"] for r in metrics_rows]\n",
    "    density = [r[\"density\"] for r in metrics_rows]\n",
    "    pairwise = [r[\"avg_pairwise_dist\"] for r in metrics_rows]\n",
    "    disc = [r[\"avg_disc\"] for r in metrics_rows]\n",
    "    disc_scaled = [d * 10000 for d in disc]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.plot(x_vals, density, color=\"#f28e2b\", lw=2, label=\"Space density\")\n",
    "    ax.plot(x_vals, pairwise, color=\"#59a14f\", lw=2, ls=\"--\", label=\"Average pairwise distance\")\n",
    "    ax.plot(x_vals, disc_scaled, color=\"#9c755f\", lw=2, ls=\":\", label=\"Average discriminative power (x1000)\")\n",
    "\n",
    "    ax.set_xlabel(\"Number of objects (|O|)\")\n",
    "    ax.set_ylabel(\"Metric value\")\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.invert_xaxis()\n",
    "    ax.grid(True, color=\"#dddddd\", linewidth=0.8)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "# ---- Evaluate per iteration (including iter 0) ----\n",
    "metrics_rows: List[Dict] = []\n",
    "\n",
    "current_tx = transactions_per_image\n",
    "current_docs = doc_sets_from_transactions(current_tx)\n",
    "\n",
    "for t in range(MERGE_ITERS + 1):\n",
    "    tx_flat = [t for tx in current_tx for t in tx]\n",
    "    _, rules_df = mine_rules(tx_flat, MIN_SUPPORT, MIN_CONF)\n",
    "    pair_rules = extract_pair_rules(rules_df)\n",
    "\n",
    "    if t % METRICS_EVERY == 0:\n",
    "        X, _ = build_doc_matrix(current_docs)\n",
    "        row = {\n",
    "            \"iter\": t,\n",
    "            \"vocab_size\": int(X.shape[1]),\n",
    "            \"density\": density_from_matrix(X),\n",
    "            \"avg_pairwise_dist\": avg_pairwise_distance(X),\n",
    "            \"avg_disc\": avg_discriminative_power(X),\n",
    "            \"num_rules\": int(len(rules_df)),\n",
    "        }\n",
    "        metrics_rows.append(row)\n",
    "\n",
    "    if t % CONF_CURVE_EVERY == 0:\n",
    "        fig_dir = os.path.join(OUTPUT_DIR, FIG_SUBDIR)\n",
    "        os.makedirs(fig_dir, exist_ok=True)\n",
    "        plot_confidence_curve(rules_df, os.path.join(fig_dir, f\"fig3_confidence_iter{t:02d}.png\"))\n",
    "\n",
    "    best = best_symmetric_pair(pair_rules)\n",
    "    if best is None or t == MERGE_ITERS:\n",
    "        break\n",
    "    avg_conf, sup, a, b = best\n",
    "    if avg_conf < MIN_SYM_CONF:\n",
    "        break\n",
    "    new_token = f\"p{t}({a}+{b})\"\n",
    "    current_tx, _ = apply_merge_to_tx_per_image(current_tx, a, b, new_token)\n",
    "    current_docs = apply_merge_to_doc_sets(current_docs, a, b, new_token)\n",
    "\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "metrics_csv = os.path.join(OUTPUT_DIR, \"metrics_over_merges.csv\")\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "print(\"Saved metrics:\", metrics_csv)\n",
    "\n",
    "plot_metric_curves(metrics_rows, os.path.join(OUTPUT_DIR, FIG_SUBDIR, \"fig4_metrics_over_merges.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac25c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m     os.makedirs(p, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_id_color_lut\u001b[39m(n_ids: \u001b[38;5;28mint\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m) -> \u001b[43mnp\u001b[49m.ndarray:\n\u001b[32m     11\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Stable LUT so word colors are consistent across images.'''\u001b[39;00m\n\u001b[32m     12\u001b[39m     rng = np.random.default_rng(seed)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# J) Visualization outputs (overlays/crops)\n",
    "# =========================\n",
    "\n",
    "def ensure_dir(p: str) -> str:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "\n",
    "def make_id_color_lut(n_ids: int, seed: int = 0) -> np.ndarray:\n",
    "    '''Stable LUT so word colors are consistent across images.'''\n",
    "    rng = np.random.default_rng(seed)\n",
    "    lut = rng.integers(0, 256, size=(n_ids, 3), dtype=np.uint8)\n",
    "    lut[0] = np.array([0, 0, 0], dtype=np.uint8)\n",
    "    return lut\n",
    "\n",
    "WORD_LUT = make_id_color_lut(K, seed=WORD_LUT_SEED)\n",
    "\n",
    "\n",
    "def word_grid_to_mosaic(grid: np.ndarray, patch: int = PATCH, lut: np.ndarray = WORD_LUT) -> np.ndarray:\n",
    "    gh, gw = grid.shape\n",
    "    color_grid = lut[grid.astype(np.int32)]\n",
    "    mosaic = np.repeat(np.repeat(color_grid, patch, axis=0), patch, axis=1)\n",
    "    return mosaic\n",
    "\n",
    "\n",
    "def overlay_word_mosaic(img_bgr: np.ndarray, word_grid: np.ndarray, patch: int = PATCH, lut: np.ndarray = WORD_LUT, alpha: float = 0.45) -> np.ndarray:\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    gh, gw = word_grid.shape\n",
    "    assert H == gh * patch and W == gw * patch, \"Grid size must match image size\"\n",
    "    mosaic = word_grid_to_mosaic(word_grid, patch=patch, lut=lut).astype(np.float32)\n",
    "    img_f = img_bgr.astype(np.float32)\n",
    "    blended = (1 - alpha) * img_f + alpha * mosaic\n",
    "    return blended.astype(np.uint8)\n",
    "\n",
    "\n",
    "def phrase_hit_map(grid: np.ndarray, a_token: str, b_token: str, neigh: int = NEIGH) -> np.ndarray:\n",
    "    # Accept base word tokens (w#) or phrase tokens (p#(...))\n",
    "    def token_ids(token: str) -> set:\n",
    "        if token.startswith('w'):\n",
    "            return {int(token[1:])}\n",
    "        if token.startswith('p') and token in PHRASE_MEMBERS:\n",
    "            return set(PHRASE_MEMBERS[token])\n",
    "        return set()\n",
    "\n",
    "    a_ids = token_ids(a_token)\n",
    "    b_ids = token_ids(b_token)\n",
    "    if not a_ids or not b_ids:\n",
    "        return np.zeros_like(grid, dtype=bool)\n",
    "\n",
    "    gh, gw = grid.shape\n",
    "    hit = np.zeros((gh, gw), dtype=bool)\n",
    "    for r in range(gh):\n",
    "        for c in range(gw):\n",
    "            r0, r1 = max(0, r - neigh), min(gh, r + neigh + 1)\n",
    "            c0, c1 = max(0, c - neigh), min(gw, c + neigh + 1)\n",
    "            window = grid[r0:r1, c0:c1]\n",
    "            has_a = np.any(np.isin(window, list(a_ids)))\n",
    "            has_b = np.any(np.isin(window, list(b_ids)))\n",
    "            hit[r, c] = bool(has_a and has_b)\n",
    "    return hit\n",
    "\n",
    "def overlay_hits_on_image(img_bgr: np.ndarray, hit_map: np.ndarray, patch: int = PATCH, alpha: float = 0.4) -> np.ndarray:\n",
    "    overlay = img_bgr.copy()\n",
    "    gh, gw = hit_map.shape\n",
    "    for r in range(gh):\n",
    "        for c in range(gw):\n",
    "            if not hit_map[r, c]:\n",
    "                continue\n",
    "            y0, y1 = r * patch, (r + 1) * patch\n",
    "            x0, x1 = c * patch, (c + 1) * patch\n",
    "            overlay[y0:y1, x0:x1] = (1 - alpha) * overlay[y0:y1, x0:x1] + alpha * np.array([0, 0, 255])\n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "mosaic_dir = ensure_dir(os.path.join(OUTPUT_DIR, \"word_mosaics\"))\n",
    "overlay_dir = ensure_dir(os.path.join(OUTPUT_DIR, \"word_overlay\"))\n",
    "compare_dir = ensure_dir(os.path.join(OUTPUT_DIR, \"word_overlay_compare\"))\n",
    "phrase_dir = ensure_dir(os.path.join(OUTPUT_DIR, \"phrase_overlays\"))\n",
    "crops_dir = ensure_dir(os.path.join(OUTPUT_DIR, \"phrase_crops\"))\n",
    "\n",
    "N_SHOW = min(N_SHOW_LIMIT, len(imgs))\n",
    "for i in range(N_SHOW):\n",
    "    grid = word_grids[i]\n",
    "    mosaic = word_grid_to_mosaic(grid)\n",
    "    cv2.imwrite(os.path.join(mosaic_dir, f\"img_{i:04d}_word_mosaic.png\"), mosaic)\n",
    "\n",
    "N_OVERLAY = min(N_OVERLAY_LIMIT, len(imgs))\n",
    "for i in range(N_OVERLAY):\n",
    "    img = imgs[i]\n",
    "    grid = word_grids[i]\n",
    "    overlay = overlay_word_mosaic(img, grid, alpha=ALPHA)\n",
    "    cv2.imwrite(os.path.join(overlay_dir, f\"img_{i:04d}_word_overlay.png\"), overlay)\n",
    "    combined = np.hstack([img, overlay])\n",
    "    cv2.imwrite(os.path.join(compare_dir, f\"img_{i:04d}_compare.png\"), combined)\n",
    "\n",
    "if merge_logs:\n",
    "    top_pairs = [m for m in merge_logs if m.get(\"best_pair\")][:min(3, len(merge_logs))]\n",
    "    for m in top_pairs:\n",
    "        a, b = m[\"best_pair\"].split(\",\")\n",
    "        for i in range(min(N_VIZ_LIMIT, len(imgs))):\n",
    "            grid = word_grids[i]\n",
    "            hit = phrase_hit_map(grid, a, b, neigh=NEIGH)\n",
    "            if hit.sum() == 0:\n",
    "                continue\n",
    "            overlay = overlay_hits_on_image(imgs[i], hit, patch=PATCH, alpha=0.4)\n",
    "            cv2.imwrite(os.path.join(phrase_dir, f\"img_{i:04d}_overlay_{a}_{b}.png\"), overlay)\n",
    "            hit_positions = np.argwhere(hit)\n",
    "            if len(hit_positions) == 0:\n",
    "                continue\n",
    "            rng = np.random.default_rng(SEED)\n",
    "            if len(hit_positions) > N_CROP_VIZ_LIMIT:\n",
    "                hit_positions = hit_positions[rng.choice(len(hit_positions), size=N_CROP_VIZ_LIMIT, replace=False)]\n",
    "            for j, (r, c) in enumerate(hit_positions[:8]):\n",
    "                cy = r * PATCH + PATCH // 2\n",
    "                cx = c * PATCH + PATCH // 2\n",
    "                half = 2 * PATCH\n",
    "                H, W = imgs[i].shape[:2]\n",
    "                y0, y1 = max(0, cy - half), min(H, cy + half)\n",
    "                x0, x1 = max(0, cx - half), min(W, cx + half)\n",
    "                crop = imgs[i][y0:y1, x0:x1]\n",
    "                cv2.imwrite(os.path.join(crops_dir, f\"img_{i:04d}_crop_{a}_{b}_{j:02d}.png\"), crop)\n",
    "\n",
    "print(\"Saved outputs under:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# K) Phrase visual evaluation (semantic sanity check)\n",
    "# =========================\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from typing import Iterable\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Adapter layer ----\n",
    "def get_frame(frame_id: int) -> np.ndarray:\n",
    "    # imgs are stored in BGR; return RGB for plotting\n",
    "    if frame_id < 0 or frame_id >= len(imgs):\n",
    "        raise IndexError(f'frame_id out of range: {frame_id}')\n",
    "    return cv2.cvtColor(imgs[frame_id], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def get_frame_path(frame_id: int) -> str:\n",
    "    return kept_paths[frame_id] if frame_id < len(kept_paths) else ''\n",
    "\n",
    "def get_phrase_members(phrase_id: str) -> list:\n",
    "    # phrase_id is token like 'p0(w12+w87)'\n",
    "    if phrase_id not in PHRASE_MEMBERS:\n",
    "        raise KeyError(f'Unknown phrase_id: {phrase_id}')\n",
    "    return list(PHRASE_MEMBERS[phrase_id])\n",
    "\n",
    "def iter_phrase_occurrences(phrase_id: str, neigh: int = NEIGH):\n",
    "    members = set(get_phrase_members(phrase_id))\n",
    "    if not members:\n",
    "        return\n",
    "    for frame_id, grid in enumerate(word_grids):\n",
    "        gh, gw = grid.shape\n",
    "        for r in range(gh):\n",
    "            for c in range(gw):\n",
    "                r0, r1 = max(0, r - neigh), min(gh, r + neigh + 1)\n",
    "                c0, c1 = max(0, c - neigh), min(gw, c + neigh + 1)\n",
    "                window = grid[r0:r1, c0:c1]\n",
    "                present = set(int(x) for x in np.unique(window)) & members\n",
    "                if not present:\n",
    "                    continue\n",
    "                strength = len(present) / max(1, len(members))\n",
    "                regions = []\n",
    "                for rr in range(r0, r1):\n",
    "                    for cc in range(c0, c1):\n",
    "                        if int(grid[rr, cc]) in present:\n",
    "                            regions.append((rr, cc))\n",
    "                yield frame_id, regions, strength, len(present)\n",
    "\n",
    "def _phrase_color(phrase_id: str) -> tuple:\n",
    "    rng = np.random.default_rng(abs(hash(phrase_id)) % (2**32))\n",
    "    color = rng.integers(64, 255, size=3).tolist()\n",
    "    return tuple(int(c) for c in color)\n",
    "\n",
    "def _draw_regions(img_rgb: np.ndarray, regions: list, patch: int = PATCH, color=(255, 0, 0), alpha=0.35) -> np.ndarray:\n",
    "    if not regions:\n",
    "        return img_rgb.copy()\n",
    "    overlay = img_rgb.copy()\n",
    "    for (r, c) in regions:\n",
    "        y0, y1 = r * patch, (r + 1) * patch\n",
    "        x0, x1 = c * patch, (c + 1) * patch\n",
    "        overlay[y0:y1, x0:x1] = (1 - alpha) * overlay[y0:y1, x0:x1] + alpha * np.array(color)\n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "def _rank_phrase_occurrences(phrase_id: str, top_n: int = 20, max_per_frame: int = 3):\n",
    "    occ = []\n",
    "    per_frame = {}\n",
    "    for frame_id, regions, strength, raw_count in iter_phrase_occurrences(phrase_id):\n",
    "        if per_frame.get(frame_id, 0) >= max_per_frame:\n",
    "            continue\n",
    "        occ.append((strength, raw_count, frame_id, regions))\n",
    "        per_frame[frame_id] = per_frame.get(frame_id, 0) + 1\n",
    "    occ.sort(key=lambda x: (x[0], x[1]), reverse=True)\n",
    "    return occ[:top_n]\n",
    "\n",
    "def run_phrase_visual_eval(phrases_to_eval: Iterable[str] = None, top_n: int = 20, out_dir: str = 'eval_phrases', overwrite: bool = False, save_individual: bool = True):\n",
    "    if phrases_to_eval is None:\n",
    "        phrases = PHRASE_TOKENS\n",
    "    else:\n",
    "        phrases = list(phrases_to_eval)\n",
    "\n",
    "    if not phrases:\n",
    "        warnings.warn('No phrases to evaluate. Run merge loop first.')\n",
    "        return\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for phrase_id in phrases:\n",
    "        phrase_dir = os.path.join(out_dir, f'phrase_{phrase_id}')\n",
    "        if os.path.exists(phrase_dir) and not overwrite:\n",
    "            warnings.warn(f'Skipping existing: {phrase_dir}')\n",
    "            continue\n",
    "        os.makedirs(phrase_dir, exist_ok=True)\n",
    "\n",
    "        members = get_phrase_members(phrase_id)\n",
    "        occ = _rank_phrase_occurrences(phrase_id, top_n=top_n, max_per_frame=3)\n",
    "        if not occ:\n",
    "            warnings.warn(f'No occurrences found for {phrase_id}')\n",
    "            continue\n",
    "\n",
    "        n = len(occ)\n",
    "        cols = 5\n",
    "        rows = int(math.ceil(n / cols))\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "        axes = np.array(axes).reshape(-1)\n",
    "\n",
    "        color = _phrase_color(phrase_id)\n",
    "        strengths = []\n",
    "\n",
    "        for idx, (strength, raw_count, frame_id, regions) in enumerate(occ):\n",
    "            strengths.append(strength)\n",
    "            try:\n",
    "                img = get_frame(frame_id)\n",
    "            except Exception as e:\n",
    "                warnings.warn(f'Failed to load frame {frame_id}: {e}')\n",
    "                axes[idx].axis('off')\n",
    "                continue\n",
    "\n",
    "            if regions:\n",
    "                img = _draw_regions(img, regions, patch=PATCH, color=color, alpha=0.35)\n",
    "            else:\n",
    "                warnings.warn(f'No spatial regions for {phrase_id} on frame {frame_id}')\n",
    "\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f'frame {frame_id} | s={strength:.2f}', fontsize=8)\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "            if save_individual:\n",
    "                out_path = os.path.join(phrase_dir, f'occ_{idx:02d}_frame_{frame_id}.png')\n",
    "                cv2.imwrite(out_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        for ax in axes[n:]:\n",
    "            ax.axis('off')\n",
    "\n",
    "        avg_strength = float(np.mean(strengths)) if strengths else 0.0\n",
    "        fig.suptitle(f'{phrase_id} | size={len(members)} | avg strength={avg_strength:.2f}', y=1.02)\n",
    "        fig.tight_layout()\n",
    "        fig_path = os.path.join(phrase_dir, 'grid.png')\n",
    "        fig.savefig(fig_path, dpi=200, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "run_phrase_visual_eval(phrases_to_eval=PHRASE_TOKENS[:10], top_n=20, out_dir='eval_phrases', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1b9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}